# 实验二：逻辑回归算法实验



|   名称   |   内容    |
| :------: | :-------: |
|   姓名   |   李鸣    |
|   学号   | 201613331 |
| 作业连接 |           |



#### 【实验目的】

1. 理解逻辑回归算法原理，掌握逻辑回归算法框架；
2. 理解逻辑回归的sigmoid函数；
3. 理解逻辑回归的损失函数；
4. 针对特定应用场景及数据，能应用逻辑回归算法解决实际分类问题;

#### 【实验内容】

1. 根据给定的数据集，编写python代码完成逻辑回归算法程序，实现如下功能：

   建立一个逻辑回归模型来预测一个学生是否会被大学录取。假设您是大学部门的管理员，您想根据申请人的两次考试成绩来确定他们的入学机会。您有来自以前申请人的历史数据，可以用作逻辑回归的训练集。对于每个培训示例，都有申请人的两次考试成绩和录取决定。您的任务是建立一个分类模型，根据这两门考试的分数估计申请人被录取的概率。

   算法步骤与要求：

   (1)读取数据；(2)绘制数据观察数据分布情况；(3)编写sigmoid函数代码；(4)编写逻辑回归代价函数代码；(5)编写梯度函数代码；(6)编写寻找最优化参数;（可使用scipy.opt.fmin_tnc()函数）；(7)编写模型评估（预测）代码，输出预测准确率；(8)寻找决策边界，画出决策边界直线图。

2. 针对iris数据集，应用sklearn库的逻辑回归算法进行类别预测。

   要求：

   （1）使用seaborn库进行数据可视化；（2）将iri数据集分为训练集和测试集(两者比例为8:2)进行三分类训练和预测；（3）输出分类结果的混淆矩阵。

#### 【实验报告要求】

1. 对照实验内容，撰写实验过程、算法及测试结果；
2. 代码规范化：命名规则、注释；
3. 实验报告中需要显示并说明涉及的数学原理公式；
4. 查阅文献，讨论逻辑回归算法的应用场景；



### 实验内容：



### 一、根据给定的数据集，编写python代码完成逻辑回归算法程序

#### 1.读取数据：

```python
# 读取相关的数据
import pandas as pd

data = pd.read_csv("/MyCode/机器学习/data/ex2data1.txt", header=None, names=['exam1','exam2','isPassed'])
data
```

输出数据：

|      |     exam1 |     exam2 | isPassed |
| ---: | --------: | --------: | -------: |
|    0 | 34.623660 | 78.024693 |        0 |
|    1 | 30.286711 | 43.894998 |        0 |
|    2 | 35.847409 | 72.902198 |        0 |
|    3 | 60.182599 | 86.308552 |        1 |
|    4 | 79.032736 | 75.344376 |        1 |
|  ... |       ... |       ... |      ... |
|   95 | 83.489163 | 48.380286 |        1 |
|   96 | 42.261701 | 87.103851 |        1 |
|   97 | 99.315009 | 68.775409 |        1 |
|   98 | 55.340018 | 64.931938 |        1 |
|   99 | 74.775893 | 89.529813 |        1 |

100 rows × 3 columns

#### 2.绘制数据观察数据分布情况：

```python
# 绘制数据看看数据的分布情况
# 数据可视化
import matplotlib.pyplot as plt

isPass = data[data['isPassed'].isin([1])]
noPass = data[data['isPassed'].isin([0])]

fig, ax = plt.subplots(figsize=(12,8))
ax.scatter(isPass['exam1'], isPass['exam2'], marker='+', label='Pass')
ax.scatter(noPass['exam1'], noPass['exam2'], marker='o', label="Didn't Pass")
ax.legend(loc=1)
ax.set_xlabel('Exam1 score')
ax.set_ylabel('Exam2 score')
ax.set_title("训练数据散点图")
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.show()
```

输出结果：

![image-20221026214300097](C:\Users\LM216\AppData\Roaming\Typora\typora-user-images\image-20221026214300097.png)

#### 3.编写sigmoid函数代码:

Sigmoid函数是一个在生物学中常见的S型函数，也称为S型生长曲线。在深度学习中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的激活函数，将变量映射到[0,1]之间。
$$
h\theta(x)=g(\theta^Tx)
$$

$$
g(z)=\frac{1}{1+e^{-z}}
$$

代码：

```python
# sigmoid函数
def sigmoid(x):
    return 1/(1+np.exp(-x))
```

#### 4.编写逻辑回归代价函数代码:

代价函数：
$$
J(\theta)=\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)-\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]
$$
代码：

```python
# 逻辑回归代价函数
def computeCost(theta,X,Y):
    theta = np.matrix(theta)  # 不能缺少，因为参数theta是一维数组，进行矩阵想乘时要把theta先转换为矩阵
    h = sigmoid(np.dot(X, (theta.T)))
    a = np.multiply(-Y, np.log(h))
    b = np.multiply((1-Y), np.log(1-h))
    return np.sum(a-b)/len(X)
```

5.编写梯度函数代码：

梯度函数：
$$
\frac{\partial J(\theta)}{\partial \theta_{j}}=\frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}
$$

```python
# 梯度函数
def gradient(theta,X,Y):
    theta = np.matrix(theta) #要先把theta转化为矩阵
    h = sigmoid(np.dot(X, (theta.T)))
    grad = np.dot(((h-Y).T), X)/len(X)
    return np.array(grad).flatten()  #因为下面寻找最优化参数的函数（opt.fmin_tnc())要求传入的gradient函返回值需要是一维数组，因此需要利用flatten（）将grad进行转换以下
```

#### 5.编写寻找最优化参数代码（可使用scipy.opt.fmin_tnc()函数）：

在实现线性回归时，是利用梯度下降的方式来寻找最优参数。
在此处使用scipy.optimize包下的fmin_tnc函数来求解最优参数，该函数利用截断牛顿算法中的梯度信息，最小化具有受边界约束的变量的函数。

```python
# 寻找最优化参数（scipy.opt.fmin_tnc()函数）
import scipy.optimize as opt

result = opt.fmin_tnc(func=computeCost, x0=theta, fprime=gradient, args=(X, Y)) 
print(result)
theta=result[0]
```

输出：

```txt
(array([-12.57917249, -12.57917249,   0.20620779,   0.20144743]), 32, 1)
```

函数常用参数值解释：
func：优化的目标函数（在这里要优化的是代价函数）。

x0：初始值，必须是一维数组 （在这里传的是一维的theta）

fprime：提供优化函数func的梯度函数，不然优化函数func必须返回函数值和梯度，或者设置approx_grad=True （在这里梯度函数是gradient函数，并且要求返回的是一维数组）。

args：元组，是传递给优化函数的参数。

#### 6.编写模型评估（预测）代码，输出预测准确率：

在求得最优theta值后，利用得到的模型在训练数据中进行预测，并求准确率。
由逻辑回归的假设模型可知：
当hθ(x)>=0.5时，预测y=1;
当hθ(x)<0.5时，预测y=0;

代码：

```python
def predict(theta, X):
    res = []
    theta = np.matrix(theta)
    temp = sigmoid(X * theta.T)
    for x in temp:
        if x >= 0.5:
            res.append(1)
        else:
            res.append(0)
    return res

predictValues=predict(theta,X)
hypothesis = []    
for (a, b) in zip(predictValues, Y):
    if a == b:
        hypothesis.append(1)
    else:
        hypothesis.append(0)

accuracy=hypothesis.count(1)/len(hypothesis)
print ('accuracy = {0}%'.format(accuracy*100))

```

predict函数：通过训练数据以及theta值进行预测，并且把预测结果使用列表返回；
hypothesis目的是将预测值与实际值进行比较，如果二者相等，则为1，否则为0；
accuracy=hypothesis.count(1)/len(hypothesis) 计算hypothesis中1的个数然后除以总的长度，得到准确率。

输出准确率：

accuracy = 89.0%

#### 7.寻找决策边界，画出决策边界直线图：

决策边界：

```python
#决策边界
def find_x2(x1,theta):
    return [(-theta[0]-theta[1]*x_1)/theta[2] for x_1 in x1]
x1 = np.linspace(30, 100, 1000)
x2=find_x2(x1,theta)
```

决策边界直线图可视化：

```python
# 获取数据
import pandas as pd

data = pd.read_csv("/MyCode/机器学习/data/ex2data1.txt", header=None, names=['exam1','exam2','isAdmitted'])
#数据可视化
admittedData=data[data['isAdmitted'].isin([1])]
noAdmittedData=data[data['isAdmitted'].isin([0])]
fig,ax=plt.subplots(figsize=(12,8))
ax.scatter(admittedData['exam1'],admittedData['exam2'],marker='+',label='addmitted')
ax.scatter(noAdmittedData['exam2'],noAdmittedData['exam1'],marker='o',label="not addmitted")
ax.plot(x1,x2,color='r',label="decision boundary")
ax.legend(loc=1)
ax.set_xlabel('Exam1 score')
ax.set_ylabel('Exam2 score')
ax.set_title("Training data with decision boundary")
plt.show()
```

![image-20221031131312980](C:\Users\LM216\AppData\Roaming\Typora\typora-user-images\image-20221031131312980.png)

### 二、针对iris数据集，应用sklearn库的逻辑回归算法进行类别预测

#### 1.使用seaborn库进行数据可视化：

读取iris数据集并查看：

```python
## 我们利用 sklearn 中自带的 iris 数据作为数据载入，并利用Pandas转化为DataFrame格式
from sklearn.datasets import load_iris
import pandas as pd

iris_features = pd.DataFrame(data=data.data, columns=data.feature_names) #利用Pandas转化为DataFrame格式
iris_features
```

输出结果：

|      | sepal length (cm) | sepal width (cm) | petal length (cm) | petal width (cm) |
| ---: | ----------------: | ---------------: | ----------------: | ---------------: |
|    0 |               5.1 |              3.5 |               1.4 |              0.2 |
|    1 |               4.9 |              3.0 |               1.4 |              0.2 |
|    2 |               4.7 |              3.2 |               1.3 |              0.2 |
|    3 |               4.6 |              3.1 |               1.5 |              0.2 |
|    4 |               5.0 |              3.6 |               1.4 |              0.2 |
|  ... |               ... |              ... |               ... |              ... |
|  145 |               6.7 |              3.0 |               5.2 |              2.3 |
|  146 |               6.3 |              2.5 |               5.0 |              1.9 |
|  147 |               6.5 |              3.0 |               5.2 |              2.0 |
|  148 |               6.2 |              3.4 |               5.4 |              2.3 |
|  149 |               5.9 |              3.0 |               5.1 |              1.8 |

150 rows × 4 columns

用seaborn进行可视化：

```python
import seaborn as sns
from sklearn.datasets import load_iris
import pandas as pd

data = load_iris() #得到数据集
iris_target = data.target #得到数据对应的标签
iris_features = pd.DataFrame(data=data.data, columns=data.feature_names) #利用Pandas转化为DataFrame格式
# 合并标签和特征信息
iris_all = iris_features.copy() ## 进行浅拷贝，防止对于原始数据的修改
iris_all['target'] = iris_target
# 特征与标签组合的散点可视化
# 在2D情况下不同的特征组合对于不同类别的花的散点分布，以及大概的区分能力。
sns.pairplot(data=iris_all,diag_kind='hist', hue= 'target')
plt.show()
```

输出结果：

![image-20221031133337553](C:\Users\LM216\AppData\Roaming\Typora\typora-user-images\image-20221031133337553.png)

#### 2.将iri数据集分为训练集和测试集(两者比例为8:2)进行三分类训练和预测

```python
from sklearn.model_selection import train_test_split
# 从sklearn中导入逻辑回归模型
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

## 测试集大小为20%， 80%/20%分
x_train, x_test, y_train, y_test = train_test_split(iris_features, iris_target, test_size = 0.2, random_state = 2020)
## 定义 逻辑回归模型
clf = LogisticRegression()
# 在训练集上训练逻辑回归模型
clf.fit(x_train, y_train)
## 查看其对应的w
print('逻辑回归的权重：\n',clf.coef_)

## 查看其对应的w0
print('逻辑回归的截距(w0):\n',clf.intercept_)

## 因为3分类，所有我们这里得到了三个逻辑回归模型的参数，其三个逻辑回归组合起来即可实现三分类。
## 在训练集和测试集上分别利用训练好的模型进行预测
train_predict = clf.predict(x_train)
test_predict = clf.predict(x_test)

## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果
print('逻辑回归准确度:',metrics.accuracy_score(y_train,train_predict))
print('逻辑回归准确度:',metrics.accuracy_score(y_test,test_predict))
```

输出结果：

```
逻辑回归的权重：
 [[-0.45928925  0.83069892 -2.26606529 -0.99743983]
 [ 0.33117319 -0.72863426 -0.06841147 -0.98711029]
 [ 0.12811606 -0.10206466  2.33447676  1.98455011]]
逻辑回归的截距(w0):
 [  9.43880649   3.93047365 -13.36928015]
逻辑回归准确度: 0.9833333333333333
逻辑回归准确度: 0.8666666666666667
```

#### 3.输出分类结果的混淆矩阵：

```python
## 查看混淆矩阵
confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)
print('混淆矩阵结果：\n',confusion_matrix_result)
```

输出结果：

```
混淆矩阵结果：
 [[10  0  0]
 [ 0  8  2]
 [ 0  2  8]]
```

### 三、讨论逻辑回归算法的应用场景

应用：

- 用于分类：适合做很多分类算法的基础组件。
- 用于预测：预测事件发生的概率（输出）。
- 用于分析：单一因素对某一个事件发生的影响因素分析（特征参数值）。

适用：

- 基本假设：输出类别服从伯努利二项分布。
- 样本线性可分。
- 特征空间不是很大的情况。
- 不必在意特征间相关性的情景。
- 后续会有大量新数据的情况。